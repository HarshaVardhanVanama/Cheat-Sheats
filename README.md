# Links 

Deep Learning

https://medium.com/inbrowserai/simple-diagrams-of-convoluted-neural-networks-39c097d2925b

http://ufldl.stanford.edu/tutorial/

Transfer Learning 

http://cs231n.github.io/transfer-learning/

https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html

Convolution Layer

http://cs231n.github.io/convolutional-networks/

http://www.iro.umontreal.ca/~bengioy/talks/DL-Tutorial-NIPS2015.pdf

https://stackoverflow.com/questions/38553927/batch-normalization-in-convolutional-neural-network - batch normalization in cnn

Alex Net

https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf

https://i0.wp.com/ramok.tech/wp-content/uploads/2017/12/2017-12-31_01h31_40.jpg

http://euler.stat.yale.edu/~tba3/stat665/lectures/lec18/notebook18.html

VGG Net:

https://www.quora.com/What-is-the-VGG-neural-network

https://arxiv.org/pdf/1409.1556.pdf

https://github.com/fchollet/deep-learning-models/blob/master/vgg16.py

ResNet:

https://arxiv.org/pdf/1512.03385.pdf

https://github.com/keras-team/keras/blob/master/keras/applications/resnet50.py

Inception Net:

https://github.com/keras-team/keras-applications/blob/master/keras_applications/inception_v3.py

http://www.ashukumar27.io/CNN-Inception-Network/

https://arxiv.org/pdf/1512.00567.pdf
 
Machine Learning

https://stanford.edu/~shervine/teaching/cs-229.html

http://explained.ai/matrix-calculus/index.html       The Matrix Calculus You Need For Deep Learning

Optimizers

http://ruder.io/optimizing-gradient-descent/

https://www.slideshare.net/SebastianRuder/optimization-for-deep-learning

https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f

https://towardsdatascience.com/stochastic-gradient-descent-with-momentum-a84097641a5d

Capsule Nets:

https://www.linkedin.com/feed/update/urn:li:activity:6448587335914258432
